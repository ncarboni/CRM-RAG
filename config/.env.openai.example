# Flask security settings
# Generate a secure random key with: python -c "import secrets; print(secrets.token_hex(32))"
# IMPORTANT: Use a persistent key in production to maintain sessions across restarts
# FLASK_SECRET_KEY=your-secret-key-here

# LLM provider settings
LLM_PROVIDER=openai
# OPENAI_API_KEY loaded from .env.secrets
OPENAI_MODEL=gpt-4o
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_MAX_TOKENS=4096
TEMPERATURE=0.7

# ── OpenAI Rate-Limit & Embedding Settings ──
# Uncomment the tier that matches your account.
# Docs: https://platform.openai.com/docs/guides/rate-limits

# --- Tier 1 (3K RPM, 1M TPM) — default ---
TOKENS_PER_MINUTE=1000000
REQUESTS_PER_MINUTE=3000
EMBEDDING_MAX_CONCURRENT=3
EMBEDDING_RETRY_ATTEMPTS=5
EMBEDDING_RETRY_DELAY=2.0
EMBEDDING_CHUNK_SIZE=2048
EMBEDDING_BATCH_SIZE=1000

# --- Tier 2 (5K RPM, 1M TPM) ---
# TOKENS_PER_MINUTE=1000000
# REQUESTS_PER_MINUTE=5000
# EMBEDDING_MAX_CONCURRENT=10
# EMBEDDING_RETRY_ATTEMPTS=3
# EMBEDDING_RETRY_DELAY=1.0
# EMBEDDING_CHUNK_SIZE=2048
# EMBEDDING_BATCH_SIZE=1000

# --- Tier 3 (5K RPM, 1M TPM) ---
# TOKENS_PER_MINUTE=1000000
# REQUESTS_PER_MINUTE=5000
# EMBEDDING_MAX_CONCURRENT=15
# EMBEDDING_RETRY_ATTEMPTS=3
# EMBEDDING_RETRY_DELAY=0.5
# EMBEDDING_CHUNK_SIZE=2048
# EMBEDDING_BATCH_SIZE=2000

# Server settings
PORT=5001
