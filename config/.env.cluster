# Cluster configuration for document generation and embedding computation
# No API keys needed - cluster only uses local embedding model

# Local embeddings (must match local config for compatibility)
EMBEDDING_PROVIDER=local
EMBEDDING_MODEL=BAAI/bge-m3
EMBEDDING_DEVICE=cuda

# Batch size for embedding
# This is the BASE batch size for short documents.
# Dynamic batching automatically reduces this for longer documents
# to prevent CUDA out-of-memory errors on variable-length datasets.
#
# For A100 (80GB) with bge-m3:
# - batch_size=128 handles most documents efficiently
# - Very long docs (>24K chars) automatically use batch_size=8
#
# See docs/PROCESSING.md for configuration details.
EMBEDDING_BATCH_SIZE=128

USE_EMBEDDING_CACHE=true
